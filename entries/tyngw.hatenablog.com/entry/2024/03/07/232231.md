---
Title: テスト設計におけるLLMとの向き合い方
Category:
- テスト設計
- テスト分析
Date: 2024-03-07T23:22:31+09:00
URL: https://tyngw.hatenablog.com/entry/2024/03/07/232231
EditURL: https://blog.hatena.ne.jp/tyngw/tyngw.hatenablog.com/atom/entry/6801883189088989959
---

AIとテストについて議論するとき、次の二つに分類し、どちらの議論をしているのかを最初に明らかにすべきと考えています。

- AI for Testing: AI「で」テストする
- Testing for AI: AI「を」テストする

今回の記事は、前者の「AI for Testing」について書いていきます。
具体的には、[1月27日に行われたテスト設計コンテスト](https://www.aster.or.jp/testcontest/open.html)にて発表した内容について、伝えきれなかった内容を書いていこうと思います。

**2025年5月11日 追記**  
2024年から2025年にかけて、LLMやそれらを利用するツール・サービスが大幅に進化しており、この記事の内容は参考にならない可能性があります。
直近の記事もご覧になることをおすすめします。
[https://tyngw.hatenablog.com/entry/2025/05/10/233310:embed]

## AIを活用する上での前提

2022年の暮れから昨年2023年のはじめはChatGPT(GPT-3.5)の話題で持ちきりでした。
実は私自身は、この話題で盛り上がる前から、Transformerの系譜であるBERT(Bidirectional Encoder Representations from Transformers)の活用については関心を持っていて、
社内で有志の研究活動をしていたりしました。( ~~大きな成果は出せませんでしたが~~)

新しいものを扱う時、その成り立ちや歴史について理解しておくことは重要だと考えています。
この記事の中で触れることはしませんが、もしTransformerについて知らない方は、参考文献を確認してみてください[^1]

ここでお伝えしたいのは、どんなにAIの精度が良くなっても正答率が100%になることはないということです。
この前提を考慮した上で、テスト設計への活用を考える必要があります。

## 考えたこと

先の活動をしている中で、にしさん(電気通信大学 故 西康晴氏)からいただいたフィードバックで、記憶に残っているフレーズがあります。

> “自分たちのやっているプロセスを一つずつ細分化していけば、AIだって何だって活用できるようになる”

(言葉のチョイスは違うかもしれないですが)

このフィードバックをいただいてから、業務としてテスト設計に取り組む際に、自分のやっていることの一つひとつを考え直してみましたが、
業務の中では時間的な制約もあり、深く考えることはできませんでした。
それから数年後、ChatGPTが登場し、そして、テスト設計コンテストに出場する機会をいただき、改めて真剣にテスト設計とは何かであったり、テスト設計にAIを活用するための方法について向き合うことになりました。

そこで、まずはJSTQB[^2]で示されているテストプロセスを改めて読み込んでみました。

- 何をテストするか、つまり、テスト要求を洗い出す「テスト分析」
- テスト分析で抽出したテスト要求をどうテストするかを考える「テスト設計」
- テストが実行可能な状態になるよう具体的な手順に落とし込むとともに、テスト環境やテストデータを準備する「テスト実装」

テストの目的には、要件が満たされていることを検証する、品質に対する信頼を積み上げる、ステークホルダに判断となる根拠を示すなど、様々なものがありますが、
その目的を果たす上で重要なのは、正確性や信頼性が求められるということです。

人間が実施しても100%の精度で実施できるとは限りませんが、人間が出力した結果は、ルールや法則から演繹的に導くことが多いのに対し、
AIが出力する成果物は、事実や事例から帰納的に導くため、出力結果の導出の根拠の信頼性が低いことが挙げられます。

そのため、導き出したテスト要求をどうテストするのかを考える「テスト設計」や、より具体化が必要な「テスト実装」の活動に、AIの出力結果を利用してしまうと、折角導き出したテスト要求が満たされているのか、説明が難しくなってしまうのではないかと考えました。

そこで、人間が発想を最も広げるプロセス「テスト分析」に活用するのが良いのではないかと考えました。

## テストプロセスにAIを組み込む際の留意点

言語モデルが大規模になればなるほど、AIの受け答え(出力結果)は、より自然で違和感のないものとなります。
一方で、前述の通り、精度が100%になることはないため、嘘が含まれることになります。(ハルシネーション)

どのテストプロセスで活用しても同様だと思いますが、人間が考えもせずに最初からAIを頼ってしまうと、
もっともらしい出力結果から思考が発散しないという懸念がありました。

そのため、AIを使うのは人間が十分に思考し、出力結果を出した後に、足りない視点がないかを確認するという使い方をしました。
[f:id:tyngw:20240307230312p:plain]

## LLMを用いたテスト分析

コンテストの中では、LLMをテスト分析に用いるための方法として、次の2つの考え方を利用させていただきました。

- 意地悪漢字[^3]
- 応用HAZOPのガイドワード[^4]

この2つの共通点は、いずれもガイドワードとして利用できる点です。
AIの仕組みを理解すれば言わずもがなの内容ですが、あくまでAIは非常に高い精度で出現する単語を予測しているに過ぎません。
そのため、インプット(プロンプト)でいかに次に出現する単語のバリエーションを広げてあげるかが重要であると考えました。

コンテストのフィードバックでは、「いずれも提案から時間が経っているので検討が十分だったか」といったご意見もいただいたのですが、
私の今の知識の中でガイドワードとして使え、尚且つISO/IEC 25010の品質モデルのように、よく知られているモデル以外を活用したかったというのがこの2つを選んだ根拠でした。
(意地悪漢字や、HAZOPガイドワードがよく知られていないというわけではないと思いますが、提案から年数が経っていることもあり、知らない方もいらっしゃるのではないかと想定していました)

実際にどのような結果が得られたのかについては、発表スライドにも書いたため、ここでは割愛しようと思いますが、
当時の最新モデル(GPT-4)を使っても、出力結果の全てがテスト分析として活用できるかというとそうではなく、
取捨選択をする必要がある印象でした。

そのため、現時点では、壁打ち相手として自分が持っていなかった視点を得るために相談するのが最適な使い方であると感じました。

[^1]: https://www.slideshare.net/ssuser3b2d02/ss-236525444
[^2]: https://jstqb.jp/syllabus.html#syllabus_foundation
[^3]: https://www.jasst.jp/archives/jasst10s/pdf/S3-9.pdf
[^4]: https://jasst.jp/symposium/jasst12tokyo/pdf/D2-1_paper.pdf



