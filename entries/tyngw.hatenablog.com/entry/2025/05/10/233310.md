---
Title: AI for Testingについてぼんやりと考えていること(答えはまだない)
Category:
- テスト設計
- テスト分析
Date: 2025-05-10T23:33:10+09:00
URL: https://tyngw.hatenablog.com/entry/2025/05/10/233310
EditURL: https://blog.hatena.ne.jp/tyngw/tyngw.hatenablog.com/atom/entry/6802418398340253291
---

## はじめに

AIすごい。
すごいのですが、AIを活用したソフトウェアテストの生成事例というのは、まだそれほど多くは見かけない気がします。  
なお、ここで言うソフトウェアテストとは、リリースにおける判断材料として用いたり、よりユーザに近い視点で要件との適合性を確認するためのテストを指します。(ブラックボックステストが中心になると思います)  

この記事を書くに至った経緯としては、Kazuさんの以下の投稿を拝見したことがきっかけでした。

[https://x.com/kz_suzuki/status/1913726366052466888:embed]



私個人としては、②の段階的に成果物を作成させ、都度人間がレビューする方法が良いのではないかと考えています。  
ごく小規模なソフトウェアであれば、直接テストケースを出してもらってレビューするだけで済むかもしれませんが、複雑なビジネス要件を満たしているのかをレビューしてもらったり、設計的に弱そうな部分、実装が複雑な部分をレビューしてもらったりと、さまざまなステークホルダからレビューを受け、**納得感のある**テスト((納得感のあるテストとはなんぞやという話は、それはそれで深いテーマなので、本稿では割愛します))に仕上げていく必要があります。  
その時に、表形式で書くことが多いテストケースで、それらのレビューができるでしょうか？  

それよりは、テスト分析から設計、実装と段階的に手段に落とし込んでいくことで、目的を追いやすくなることでレビュー容易性が向上し、ステークホルダに対して**納得感のある**テストを提供できるのではないでしょうか。

## どのようにして段階的にレビューをしていくのか

では、AIに生成させた成果物を段階的にレビューをしていくためには、どのような手段を取るのが良いのでしょうか。  
2025年5月現在、私自身で明確な手順を持っているわけではありませんが、ぼんやりとしたイメージだけはあるので、それをお伝えします。


[https://x.com/tyngw/status/1916004845321941090:embed]


先日、上記のような投稿を行いましたが、要件定義のツールであるRDRA((https://www.rdra.jp/))の一部のフェーズをLLMが支援するRDRAZeroOneが一つのヒントになりうるのではないかと思いました。  
自然言語ではあるものの、ある程度の構造化された文章(モデル)に落とし込むことで、人間がレビューや修正を行いながら、要件の叩き台を作成することができるのが特徴です。  

<figure class="figure-image figure-image-fotolife" title="RDRAZeroOne">[f:id:tyngw:20250510233119p:plain]<figcaption>RDRAZeroOneの使用風景。存在しない架空のシステムです。</figcaption></figure>

ソフトウェアテストにおいても、テスト分析・設計・実装と、段階毎に異なる表現・抽象度で目的を達成するための手段を具体化していくことになりますが、上記のように、定型化されていて、尚且つ、構造化されたモデルに落とし込んで、段階的にレビューと修正を行うことで、より目的に沿ったテストが実現できるのではないかと考えています。
